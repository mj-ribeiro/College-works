curve((0.1*x), add=T)
plot(abs(rnorm(30,0,1)), col='gray', lwd=19)
curve((0.1*x), add=T)
plot(abs(rnorm(30,0,1)), col='gray', lwd=19, size=3)
plot(abs(rnorm(30,0,1)), col='gray', lwd=19)
curve((0.1*x), add=T)
plot(abs(rnorm(30,0,1)), col='gray', lwd=19)
curve((0.1*x), add=T, col='red')
curve(dnorm(x))
curve(dnorm(x), xlim=c(-1,1))
curve(dnorm(x), xlim=c(-3,3))
curve(dnorm(x), xlim=c(-4,4))
curve(dnorm(x), xlim=c(-6,6))
curve(dnorm(x), xlim=c(-8,8))
write.csv(ret, 'ret')
write.table(ret, 'ret')
write.xlsx(ret, 'ret')
library(xlsx)
write.xlsx(ret, 'ret')
write.xlsx(ret, 'c:/ret.xlsx')
write.xlsx(ret,"C:/Users/user/Documents/ret.xlsx")
spec2 = ugarchspec(variance.model=list(model="sGARCH",
garchOrder=c(1,1)),
mean.model=list(armaOrder=c(0,0), include.mean=TRUE),
distribution.model="norm")
garch3 = ugarchfit(spec = spec2, data= ret)
garch3
spec1 = ugarchspec(variance.model=list(model="fGARCH",
garchOrder=c(1,1), submodel='TGARCH'),
mean.model=list(armaOrder=c(0,0), include.mean=TRUE, archm=T),
distribution.model="norm")
garch2 = ugarchfit(spec = spec1, data= ret)
garch2
sd(ret)
library(sn)
curve(dsn(x))
curve(dsn(x), ylim=c(-8,8))
curve(dsn(x), ylim=c(0,8))
curve(dsn(x, xi = 2), ylim=c(0,8))
curve(dsn(x, xi = 2, omega = 0.2, alpha = 0.22), ylim=c(0,8))
curve(dsn(x, xi = 2, omega = 0.2, alpha = 0.22))
curve(dsn(x, xi = 22, omega = 0.2, alpha = 0.22))
curve(dsn(x, omega = 0.2, alpha = 0.22))
curve(dsn(x, omega = 3, alpha = 0.22))
curve(dsn(x, omega = 8, alpha = 0.22))
curve(dsn(x, omega = 8, alpha = 0.22), , ylim=c(0,8))
curve(dsn(x, omega = 8, alpha = 0.22), , ylim=c(-8,8))
curve(dsn(x, omega = 8, alpha = 0.22), , ylim=c(0,8))
curve(dsn(x, omega = 8, alpha = 0.22), , ylim=c(0,0.8))
curve(dsn(x, omega = 8, alpha = 0.22))
curve(dsn(x, omega = 0.11, alpha = 0.22))
curve(dsn(x, omega = 0.21, alpha = 0.22))
curve(dsn(x, omega = 0.41, alpha = 0.22))
curve(dsn(x, omega = 0.1, alpha = 0.22))
curve(dsn(x, omega = 0.1, alpha = 2))
curve(dsn(x, omega = 0.1, alpha = 10))
curve(dsn(x, omega = 0.1, alpha = 100))
curve(dsn(x, omega = 0.1, alpha = 0.011))
curve(dst(x, omega = 0.1, alpha = 0.011))
curve(dst(x, omega = 1, alpha = 0.011))
curve(dst(x, omega = 1, alpha = 0.11))
curve(dst(x, omega = 1, alpha = 11))
curve(dst(x, omega = 0.9, alpha = 11))
curve(dst(x, omega = 0.11, alpha = 11))
curve(dst(x, omega = 0.11, alpha = 0.11))
rst(x, omega = 0.11, alpha = 0.11))
rst(100, omega = 0.11, alpha = 0.11))
rst(100, omega = 0.11, alpha = 0.11)
rst(100, omega = 0.2, alpha = 0.11, xi = 2)
rst(100, omega = 0.2, alpha = 0.11, xi = 0)
rst(100, omega = 0.2, alpha = 0.11, xi = 0, nu = 2)
sin(30)
sin(30°)
sin(30)
sin(pi/6)
tan(pi/6)
curve(sin(x))
curve(sin(x), xlim = c(-3,3))
curve(sin(x), xlim = c(-30,30))
curve(sin(x), xlim = c(-10,10))
line(h=0)
aline(h=0)
abline(h=0)
curve(tan(x), xlim = c(-10,10))
curve(tan(x), xlim = c(-10,10))
abline(h=0)
curve((x), xlim = c(-10,10))
abline(v=0)
curve((x), xlim = c(0,10))
abline(v=0)
abline(v=10)
curve((x), xlim = c(0,10))
abline(v=10)
atan(1)
atan(pi)
pi/4
tan(pi/3)
tan(2*pi/3)
fd = function(x, alpha){
disf = exp(-x^alpha)
}
fd(2, 1)
fd = function(x, alpha){
disf = exp(-x^alpha)
return(disf)
}
fd(2, 1)
fd(0.2, 1)
curve(fd(x, 1))
curve(fd(x, 1), xlim = c(-10,10))
fd = function(x, alpha){
disf = exp(-x^(-alpha))
return(disf)
}
curve(fd(x, 1), xlim = c(-10,10))
curve(fd(x, 1), xlim = c(0,10))
curve(fd(x, 1), xlim = c(0,4))
install.packages('Rtolls40')
install.packages('Rtolls')
library(installr)
updateR()
updateR()
install.packages('Rtolls')
install.packages(c("fGarch", "forecast", "installr", "quantmod", "rugarch", "timeSeries", "tseries", "vars", "xlsx"))
install.packages('Rtolls')
install.packages('Rtolls40')
install.packages('rtolls40')
curve(x^0.4)
curve(x^0.4, ylim = c(0, 4))
curve(x^0.4, ylim = c(0, 1))
curve(x^0.2, ylim = c(0, 1))
curve(x^0.1, ylim = c(0, 1))
curve(x^0.01, ylim = c(0, 1))
curve(x^0.001, ylim = c(0, 1))
curve(x^0.1, ylim = c(0, 1))
curve(x^1, ylim = c(0, 1))
curve(x^0.1, ylim = c(0, 1))
curve(x^0.2, ylim = c(0, 1))
curve(x^0.4, ylim = c(0, 1), add=T)
install.packages("knitr")
install.packages("readxl")
# Defining my work diretory
setwd("C:/Users/user/Downloads/ML_work/Algorithm")
library(readxl)
teste <- read_excel("teste.xlsx")
teste$foot = NULL
df2 = teste[,'sex']
teste[,'sex']=NULL
teste$sex = df2
teste = data.frame(teste)
#--- function
naive_marcos2 = function(k, df){
df = as.data.frame(df)
#fator =  factor(df[,k])
a = prop.table(table(df[ ,k]))
ta = length(a)
nm = rownames(a)
print('Marcos Naive Bayes Classifier for Discrete Predictors')
cat('A-priori probabilities:\n')
#df2 = df[ , k]
print(a)
#df[ ,k] = NULL
#col_n = colnames(df)
#df[,k] = df2
M = array(0, dim = c(2,2, ta))
m = matrix(0, 2, 2)
for(g in 1:ta){
m1 = as.matrix(tapply(df[,1], df[,k], mean)[g])
v1 = as.matrix(tapply(df[,1], df[,k], sd)[g])
m2 = tapply(df[,2], df[,k], mean)[g]
v2 = tapply(df[,2], df[,k], sd)[g]
m = matrix(c(m1, m2, v1, v2)  )
M[, ,g] = m
cat(nm[g], '\n')
print(M[, ,g])
}
return(M)
}
cc = naive_marcos2('sex', teste)
library(readxl)
teste <- read_excel("teste.xlsx")
setwd("C:/Users/user/Downloads/ML_work/Algorithm")
getwd()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "D:/Git projects/college_works/ML_1")
library(knitr)
library(kableExtra)
#options(kableExtra.latex.load_packages = FALSE)
library(magrittr)
knitr:: kable(a, booktabs = T) %>%kable_styling(full_width = T) %>%
column_spec(1, width = "8cm")
library(magrittr)
knitr::kable(a)
library(tinytex)
remove.packages("tinytex", lib="~/R/win-library/4.0")
install.packages('tinytex')
knit_with_parameters('C:/Users/user/Downloads/ML_work/testemarkdown/MJ_Ribeiro.Rmd')
library(tinytex)
library(tinytex)
source('D:/Git projects/college_works/eco_fin/algoritms_ecofin_SÓRAV.R')
métricas = data.frame(matrix(, nrow=6, ncol=10))
row.names(métricas) = c('Multilogit', 'Redes neurais','KNN', 'Random Forests', 'XGboost')
colnames(métricas) = c("Acurácia", "CPC", "Sensibilidade", "Especificidade", "G", "LP", "LR", "DP", "gamma", "BA")
métricas[1, ] = metrics(cm_ml)
métricas[2, ] = metrics(cm_NN)
métricas[3, ] = metrics(cm_knn)
métricas[4, ] = metrics(cm_rf)
métricas[5, ] = metrics(cm_xg)
métricas[6, ] = metrics(cm_svm)
métricas = round( métricas, 4)
métricas = t(métricas)
métricas = data.frame(matrix(, nrow=6, ncol=10))
row.names(métricas) = c('Multilogit', 'Redes neurais','KNN', 'Random Forests', 'XGboost', 'SVM')
colnames(métricas) = c("Acurácia", "CPC", "Sensibilidade", "Especificidade", "G", "LP", "LR", "DP", "gamma", "BA")
métricas[1, ] = metrics(cm_ml)
métricas[2, ] = metrics(cm_NN)
métricas[3, ] = metrics(cm_knn)
métricas[4, ] = metrics(cm_rf)
métricas[5, ] = metrics(cm_xg)
métricas[6, ] = metrics(cm_svm)
métricas = round( métricas, 4)
métricas = t(métricas)
print(xtable(métricas, type = "latex", digits=4), file = "sóRAV.tex")
source('D:/Git projects/college_works/eco_fin/algoritms_ecofin_RAV.R')
source('D:/Git projects/college_works/eco_fin/algoritms_ecofin_SEMRAV.R')
métricas = data.frame(matrix(, nrow=5, ncol=10))
row.names(métricas) = c('Multilogit', 'Redes neurais','KNN', 'Random Forests', 'XGboost')
colnames(métricas) = c("Acurácia" ,"CPC", "Sensibilidade", "Especificidade", "G", "LP", "LR", "DP", "gamma", "BA")
métricas[1, ] = metrics(cm_ml)
métricas[2, ] = metrics(cm_nn)
métricas[3, ] = metrics(cm_knn)
métricas[4, ] = metrics(cm_rf)
métricas[5, ] = metrics(cm_xg)
métricas[6, ] = metrics(cm_svm)
métricas = round( métricas, 4)
métricas = t(métricas)
print(xtable(métricas, type = "latex", digits=4), file = "semRAV.tex")
model_e = train(as.factor(crise) ~  rav, data=df3,
trControl = control_train,
method='knn')
model_e
cm_knn = confusionMatrix(model_e)
confusionMatrix(model_e)
source('D:/Git projects/college_works/eco_fin/algoritms_ecofin_SÓRAV.R')
métricas
setwd("D:/Git projects/college_works/monitoring_macro")
# see : https://www.scielo.br/scielo.php?script=sci_arttext&pid=S0101-41612017000100039
library(GetBCBData)
library('xts')
# inflation - Índice nacional de preços ao consumidor-amplo (IPCA)
inf = gbcbd_get_series(433, first.date= '1981-01-01', last.date = '2020-04-01',
format.data = "long", be.quiet = FALSE)[ ,1:2]
data = inf$ref.date
inf[,1]=NULL
colnames(inf) = 'inf'
inf = xts(inf, order.by = data)
plot(inf)
des = gbcbd_get_series(24369, first.date= '1981-01-01', last.date = '2020-04-01',
format.data = "long", be.quiet = FALSE)[ ,1:2]
data1 = des$ref.date
des[,1]=NULL
colnames(des) = 'des'
des = xts(des, order.by = data1)
plot(des)
library(ggplot2)
plot(des)
df = data.frame(des, dinf[index(des)],inf[index(des)])
data3 = index(inf)
dfinf = data.frame(data3, inf)
ggplot(data=dfinf, aes(y=`inf`, x=`data3`), alpha=0.5)+geom_line()
windows()
g1 = ggplot(data = df[1:40,], aes(x = `des`, y =`inf`), alpha=0.5)
g1 + geom_point(color='blue', size=2) +
ggtitle('Phillips Curve') +
geom_smooth(method = 'lm',formula = y~x, color='black') +
xlab('Unemployment') +
ylab('Rate of change in inflation') +
theme(axis.title.x = element_text(colour = 'black', size=13),
axis.title.y = element_text(colour = 'black', size=13),
plot.title = element_text(hjust = 0.5))
windows()
g1 = ggplot(data = df[1:40,], aes(x = `des`, y =`inf`), alpha=0.5)
g1 + geom_point(color='blue', size=2) +
ggtitle('Phillips Curve') +
geom_smooth(method = 'lm',formula = y~x, color='black') +
xlab('Unemployment') +
ylab('Rate of change in inflation') +
theme(axis.title.x = element_text(colour = 'black', size=13),
axis.title.y = element_text(colour = 'black', size=13),
plot.title = element_text(hjust = 0.5))
plot(des)
plot(inf)
ggplot(data=dfinf, aes(y=`inf`, x=`data3`), alpha=0.5)+geom_line()
g1 = ggplot(data = df[1:40,], aes(x = `des`, y =`inf`), alpha=0.5)
g1 + geom_point(color='blue', size=2) +
ggtitle('Phillips Curve') +
geom_smooth(method = 'lm',formula = y~x, color='black') +
xlab('Unemployment') +
ylab('Rate of change in inflation') +
theme(axis.title.x = element_text(colour = 'black', size=13),
axis.title.y = element_text(colour = 'black', size=13),
plot.title = element_text(hjust = 0.5))
df = data.frame(des, dinf[index(des)],inf[index(des)])
df = data.frame(des, inf[index(des)])
g1 = ggplot(data = df[1:40,], aes(x = `des`, y =`inf`), alpha=0.5)
g1 + geom_point(color='blue', size=2) +
ggtitle('Phillips Curve') +
geom_smooth(method = 'lm',formula = y~x, color='black') +
xlab('Unemployment') +
ylab('Rate of change in inflation') +
theme(axis.title.x = element_text(colour = 'black', size=13),
axis.title.y = element_text(colour = 'black', size=13),
plot.title = element_text(hjust = 0.5))
reg1 = lm(inf ~ des, data = df)
summary(reg1)
View(df)
reg1 = lm(100*inf ~ 100*des, data = df)
df*100
df/100
reg1 = lm(inf ~ des, data = (df/100))
summary(reg1)
0.009876/0.053953
métricas
model_e = train(as.factor(crise) ~  rav, data=df3,
trControl = control_train,
method='knn')
cm_knn = confusionMatrix(model_e)
métricas[3, ] = metrics(cm_knn)
métricas = data.frame(matrix(, nrow=6, ncol=10))
row.names(métricas) = c('Multilogit', 'Redes neurais','KNN', 'Random Forests', 'XGboost', 'SVM')
colnames(métricas) = c("Acurácia", "CPC", "Sensibilidade", "Especificidade", "G", "LP", "LR", "DP", "gamma", "BA")
métricas[1, ] = metrics(cm_ml)
métricas[2, ] = metrics(cm_NN)
métricas[3, ] = metrics(cm_knn)
métricas[4, ] = metrics(cm_rf)
métricas[5, ] = metrics(cm_xg)
métricas[6, ] = metrics(cm_svm)
métricas = round( métricas, 4)
métricas = t(métricas)
métricas
métricas = data.frame(matrix(, nrow=5, ncol=10))
row.names(métricas) = c('Multilogit', 'Redes neurais','SVM', 'Random Forests', 'XGboost')
colnames(métricas) = c("Acurácia", "CPC", "Sensibilidade", "Especificidade", "G", "LP", "LR", "DP", "gamma", "BA")
métricas[1, ] = metrics(cm_ml)
métricas[2, ] = metrics(cm_NN)
métricas[3, ] = metrics(cm_svm)
métricas[4, ] = metrics(cm_rf)
métricas[5, ] = metrics(cm_xg)
métricas = round( métricas, 4)
métricas = t(métricas)
métricas
print(xtable(métricas, type = "latex", digits=4), file = "semRAV.tex")
print(xtable(métricas, type = "latex", digits=4), file = "semRAV.tex")
métricas = data.frame(matrix(, nrow=5, ncol=10))
row.names(métricas) = c('Multilogit', 'Redes neurais','SVM', 'Random Forests', 'XGboost')
colnames(métricas) = c("Acurácia", "CPC", "Sensibilidade", "Especificidade", "G", "LP", "LR", "DP", "gamma", "BA")
métricas[1, ] = metrics(cm_ml)
métricas[2, ] = metrics(cm_NN)
métricas[3, ] = metrics(cm_svm)
métricas[4, ] = metrics(cm_rf)
métricas[5, ] = metrics(cm_xg)
métricas = round( métricas, 4)
métricas = t(métricas)
métricas
print(xtable(métricas, type = "latex", digits=4), file = "semRAV.tex")
print(xtable(métricas, type = "latex", digits=4), file = "semRAV.tex")
setwd("D:/Git projects/college_works/eco_fin")
print(xtable(métricas, type = "latex", digits=4), file = "semRAV.tex")
tune_grid <- expand.grid(nrounds = 200,
max_depth = 5,
eta = 0.05,
gamma = 0.01,
colsample_bytree = 0.75,
min_child_weight = 0,
subsample = 0.5)
# rav
model_i = train(as.factor(crise) ~  rav, data=df3,
method = "xgbTree",
trControl=control_train,
tuneGrid = tune_grid,
tuneLength = 10)
cm_xg = confusionMatrix(model_i)
confusionMatrix(model_i)
print(metrics(cm_xg))
model_i = train(as.factor(crise) ~  rav, data=df3,
method = "xgbTree",
trControl=control_train,
tuneGrid = tune_grid,
tuneLength = 10)
cm_xg = confusionMatrix(model_i)
print(metrics(cm_xg))
metrics = function(cm){
acurácia = (cm[["table"]][1,1] + cm[["table"]][2,2])/sum(cm[["table"]])
cpc = cm[["table"]][2,2] / ( cm[["table"]][1,2] + cm[["table"]][2,2] )
sensibilidade = cm[["table"]][1,1] / ( cm[["table"]][1,1] + cm[["table"]][2,1] )
especificidade = cm[["table"]][2,2] /( cm[["table"]][2,2] + cm[["table"]][1,2] )
G = sqrt(sensibilidade*especificidade)
LP = sensibilidade/(1 - especificidade)
LR = (1 - sensibilidade)/(especificidade)
DP = sqrt(pi)/3 * ( log(sensibilidade/(1 - sensibilidade) ) + log( especificidade/(1 - especificidade) )  )
gamma = sensibilidade - (1 - especificidade)
BA = (1/2) * (sensibilidade + especificidade)
métricas = data.frame(acurácia, cpc, sensibilidade, especificidade, G, LP, LR, DP, gamma, BA)
}
source('D:/Git projects/college_works/eco_fin/algoritms_ecofin_RAV.R')
métricas
model_i = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
method = "xgbTree",
trControl=control_train,
tuneGrid = tune_grid,
metric = 'roc'
tuneLength = 10)
model_i = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
method = "xgbTree",
trControl=control_train,
tuneGrid = tune_grid,
metric = 'roc',
tuneLength = 10)
ggplot(model_i)
model_i = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
method = "xgbTree",
trControl=control_train,
tuneGrid = tune_grid,
tuneLength = 10)
confusionMatrix(model_i)
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=600,
MaxNWts=1500
)
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='mlp', threshold = 0.3,
maxit=600,
MaxNWts=1500
)
install.packages('RSNNS')
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='mlp', threshold = 0.3,
maxit=600,
MaxNWts=1500
)
control_train = trainControl(method = 'repeatedcv', number = 10, repeats = 2)    # ten fold
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='mlp', threshold = 0.3,
maxit=100,
#MaxNWts=100
)
model_a
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=100,
#MaxNWts=100
)
model_a
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=100,
size=5
)
model_a
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=1000,
size=5
)
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=100,
MaxNWts=1000
)
model_a
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=300,
MaxNWts=1000
)
model_a
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=500,
MaxNWts=1100
)
model_a
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=700,
MaxNWts=1300
)
model_a
control_train = trainControl(method = 'repeatedcv', number = 10, repeats = 10)    # ten fold
model_a = train(as.factor(crise) ~  gold + embi + oil + cb + rav + cdi, data=df3,
trControl = control_train,
method='nnet', threshold = 0.3,
maxit=700,
MaxNWts=1300
)
model_a
confusionMatrix(model_a)
a=print(xtable(métricas, type = "latex", digits=4), file = "sóRAV.tex")
a
métricas
