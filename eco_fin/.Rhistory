t_min = 0
n = 500000
s = 0
nn = 100
I = c()
for (j in 1:nn) {
for (i in 1:n) {
theta = runif(1, min=t_min, max=t_max)
f_ = f(2, 1/3)
s = s + f_
}
I[j] = (t_max - t_min)/n *s
}
mean(I)
sd(I)
hist(I)
for (j in 1:nn) {
s = 0
for (i in 1:n) {
theta = runif(1, min=t_min, max=t_max)
f_ = f(2, 1/3)
s = s + f_
}
I[j] = (t_max - t_min)/n *s
}
mean(I)
sd(I)
hist(I, breaks = 30, col='lightgreen')
hist(I, breaks = 30, col='lightgreen', main='Histogram of Integral values')
m = 1e+5
y = numeric(m)
phi = numeric(m)
curve(rbeta(x, 2, 2))
curve(pbeta(x, 2, 2))
curve(pbeta(x, 2, 20))
curve(pbeta(x, 2, 2))
curve(pbeta(x, 20, 2))
curve(pbeta(x, 10, 2))
curve(pbeta(x, 10, 20))
m = 1e+5
y = numeric(m)
phi = numeric(m)
for(i in 1:m){
phi[i] = rbeta(1, 2, 2)
y[i] = rbinom(1, size = 10, phi[i])
}
phi = rbeta(1, 2, 2)
y = rbinom(1, size = 10, phi)
hist(phi)
hist(y)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 1, 0.3)
rbinom(1, size = 1, 0.3)
rbinom(1, size = 1, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 2, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbinom(1, size = 10, 0.3)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
rbeta(1, 2, 2)
table(y)
phi = rbeta(1, 2, 2)
y = rbinom(1, size = 10, phi)
table(y)
hist(y)
y = rbinom(1, size = 10, phi)
table(y)
phi = rbeta(m, 2, 2)
y = rbinom(m, size = 10, phi)
table(y)
table(y)/m
plot(table(y)/m)
plot(table(y)/m, main='Beta Binomial distribution of y')
plot(table(y)/m, main='Beta Binomial distribution of y', ylabel='Probability')
plot(table(y)/m, main='Beta Binomial distribution of y', ylab='Probability')
plot(table(y)/m, main='Beta Binomial distribution of y')
plot(table(y)/m, main='Beta Binomial distribution of y', ylab='Probability')
plot(table(y)/m, main='Beta Binomial distribution of y', ylab='Probability')
81/256
81/256*1500
500/474.61
1.053497^(-1/4)
81/256*1500*2^(-4)
(1.5*0.03)/0.03
1.5^2
0.76+2.26
0.76+3.78
1/0.987
500^0.25
500^0.25* 1500^(-1/4)
500^0.25* 1500^(-1/4)*3/4
1.054^(-1/4)
81/256*1500
81/256*1500
500/(81/256*1500)
(500/(81/256*1500) )^(-1/4)
500^(1/4)*1500^(-1/4)*(86/256)^(1/4)
500/1500
81/256
0.33333/0.3164
(1500/(81/256*500) )^(-1/4)
(1500/(81/256*500) )
(1500/(81/256*500) )^(-1/4)
81/256*500*2^(-4)
10/17
0.6*17
1/(1-0.68)
120/18
9*0.6
8*0.6
exp(4.76)
exp(4.7592)
0.13*19
exp(4.31)
exp(4.3)
exp(4.29)
exp(4.2866)
exp(4.2834)
exp(3.31)
exp(2.14)
exp(3.196)
exp(12.3)
exp(3.196)
exp(3.15)
exp(2.61)
exp(2.6)
exp(2.3819)
exp(2.3196)
exp(2.28)
exp(2.22)
exp(2.2195)
exp(1.95)
exp(1.84)
exp(0.1951)
exp(0.177)
exp(0.14)
exp(0.1491)
exp(0.0969)
exp(0.0674)
exp(0.0627)
exp(0.0556)
exp(0.0532)
exp(0.0532)
exp(0.0531)
exp(0.0491)
exp(0.041)
exp(0.0242)
exp(0.0188)
#***********************************************************************************************
#                                   Algorithms without rav
#***********************************************************************************************
setwd("D:/Git projects/college_works/eco_fin")
# functions
metrics = function(cm){
acurácia = (cm[["table"]][1,1] + cm[["table"]][2,2])/sum(cm[["table"]])
cpc = cm[["table"]][2,2] / ( cm[["table"]][1,2] + cm[["table"]][2,2] )
epc = cm[["table"]][1,1] / ( cm[["table"]][2,1] + cm[["table"]][1,1] )
sensibilidade = cm[["table"]][1,1] / ( cm[["table"]][1,1] + cm[["table"]][2,1] )
especificidade = cm[["table"]][2,2] /( cm[["table"]][2,2] + cm[["table"]][1,2] )
G = sqrt(sensibilidade*especificidade)
LP = sensibilidade/(1 - especificidade)
LR = (1 - sensibilidade)/(especificidade)
DP = sqrt(pi)/3 * ( log(sensibilidade/(1 - sensibilidade) ) + log( especificidade/(1 - especificidade) )  )
gamma = sensibilidade - (1 - especificidade)
BA = (1/2) * (sensibilidade + especificidade)
métricas = data.frame(acurácia, cpc, epc, sensibilidade, especificidade, G, LP, LR, DP, gamma, BA)
}
# libraries
library('xtable')
library(caret)
library(ROSE)
library('randomForest')
#--- load variables
df = readRDS('df.rds')
#df$rexc = as.numeric(df$rexc)
#df$embi = as.numeric(df$embi)
keep = c('crise2', 'gold',  'embi',  'oil', 'cb', 'rexc',  'cdi')
df6 = df[,keep]
#--- Rose library
library(ROSE)
df3 = ovun.sample(as.factor(crise2)~., data=df6, method="both", p=0.50,
subset=options("subset")$subset,
na.action=options("na.action")$na.action, seed=1)
df3 = data.frame(df3$data)
prop.table(table(df3$crise2))
control_train = trainControl(method = 'repeatedcv', number = 10, repeats = 20)    # ten fold
View(df3)
#*********************************************************************************************
#                                     Data
#**********************************************************************************************
setwd("D:/Git projects/college_works/eco_fin")
#------------- CMAX Function
# w é o tamanho da janela
# n é a quantidade de janelas
# s é o vetor que vou passar a função
CMAX = function(w, n, s){
l = matrix(nrow=n,ncol = (w+1))
max = matrix(nrow=n, ncol = 1)
cmax = matrix(nrow=n, ncol = 1)
for (j in 1:n){
l[j, 1:(w+1)] = s[j:(w+j)]
max[j] = max(l[j, 1:(w+1)])
cmax[j] = l[j, (w+1)]/max(max[j])
}
return(cmax)
}
#### get first day
firstDayMonth=function(x)
{
x=as.Date(as.character(x))
day = format(x,format="%d")
monthYr = format(x,format="%Y-%m")
y = tapply(day,monthYr, min)
first=as.Date(paste(row.names(y),y,sep="-"))
#as.factor(first)
as.Date(first)
}
# Libraries
library(lubridate)
library(tseries)
library(timeSeries)
library(quantmod)
library(fGarch)
library(GetBCBData)
library(ipeadatar)
library(knitr);
library(tidyr);
library(dplyr);
library(DT);
library(magrittr)
library(data.table)
# Get data
ibov = getSymbols('^BVSP', src='yahoo',
from= '1999-01-01',
to = '2020-05-01',
periodicity = "monthly",    # IBOV mensal
auto.assign = F)[,4]
colnames(ibov) = 'ibov'
ibov = ibov[is.na(ibov)==F]
# VIX
vix = getSymbols('^VIX', src='yahoo',
periodicity = "monthly",
from= '2000-01-01',
to = '2020-05-01',
auto.assign = F)[,4]
colnames(vix) = 'vix'
rvix = diff(log(vix))
colnames(rvix) =  'rvix'
# Oil price
oil = getSymbols('CL=F', src='yahoo',
periodicity = "monthly",
from= '2000-01-01',
to = '2020-05-01',
auto.assign = F)[,4]
colnames(oil) = 'oil'
# Gold price
gold = getSymbols('GC=F', src='yahoo',
periodicity = "monthly",
from= '2000-01-01',
to = '2020-05-01',
auto.assign = F)[,4]
colnames(gold) = 'gold'
# 11768 - Índice da taxa de câmbio real (INPC)
cb = gbcbd_get_series(11768, first.date= '2000-01-01', last.date = '2020-05-01',
format.data = "long", be.quiet = FALSE)[ ,1:2]
data = cb$ref.date
cb[,1]=NULL
cb = xts(cb, order.by = data)
rownames(cb) = data    # colocar a data como índice
colnames(cb) = 'cb'
# cdi
cdi = gbcbd_get_series(4391, first.date= '2000-01-01', last.date = '2020-05-01',
format.data = "long", be.quiet = FALSE)[ ,1:2]
data = cdi$ref.date
cdi[,1]= NULL
cdi = xts(cdi, order.by = data)
rownames(cdi) = data    # colocar a data como índice
colnames(cdi) = 'cdi'
## EMBI
embi_search = as.data.frame(search_series(terms = c('EMBI'), fields = c("name"),language = c("br")))
embi_search %<>% dplyr::slice(1:500L)
datatable(embi_search)
embi = ipeadata(c('JPM366_EMBI366'))[,2:3]
colnames(embi) = c('date', 'embi')
k= firstDayMonth(embi$date)
k = as.Date(k)
k = as.data.frame(k)
colnames(k) = 'date'
setDT(embi)
setDT(k)
embi = embi[k, on = c('date')]
embi$date = as.Date(embi$date)
mday(embi$date) = 1   # transformar os dias do vetor de datas k em 1 (lubridate)
embi = xts(embi, order.by = embi$date)
embi = embi[,-1]
# risk aversion
rav = read.csv('kalman.csv', header = T, sep = ',', )[,1:2]
rav$data = as.Date(rav$data, format = '%m/%d/%Y')
colnames(rav) = c('date', 'rav')
s = firstDayMonth(rav$date)
s = data.frame(s)
colnames(s) = c('date')
setDT(rav)
setDT(s)
rav = rav[s, on = c('date')]
mday(rav$date) = 1   # transformar os dias do vetor de datas  em 1 (lubridate)
rav = xts(rav, order.by = rav$date)
rav = rav[,-1]
# AV
av = read.csv('av.csv', header = T, sep = ';', )[,1:2]
colnames(av) = c('date', 'av')
av$av = as.numeric(av$av)
av$date = as.Date(av$date, format = '%d/%m/%Y')
a = av$date
av = xts(av, order.by = a)
av = av[ ,'av', drop=F]
# returns
ret = diff(log(ibov))
ret = ret[is.na(ret)==F]
colnames(ret) = 'ret'
####  State space in excess of return
rexc = read.csv('rexc.csv', header = T, sep=';' )
colnames(rexc) = c('date', 'rexc')
rexc$date = as.Date(rexc$date)
a = rexc$date
rexc = xts(rexc, order.by = a)
rexc = rexc[ ,'rexc', drop=F]
#------ Using CMAX function
cm2 = CMAX(12,(length(ibov)-12), ibov )
var1 = quantile(cm2, 0.05)
var2 = quantile(cm2, 0.1)
lim = mean(cm2)-2*sd(cm2)
cm2[cm2<lim]
sum((cm2<lim)*1)   # count
# get the data of ibov
data = index(ibov)
data1 = data[13:length(ibov)]
# transform cmax in xts object
cmts = xts(x=cm2, order.by = data1)
#----- Create Dummy
# var1
crise = matrix(nrow = length(cmts))
crise = ifelse(cm2<var1, 1, 0)
pos0 = which(crise==1)   # pegar a posição onde crise== 1
pos0
for(i in 2:length(pos)){
crise[(pos[i]-12):pos[i]] = 1
}
pos1 = which(crise==1)   # pegar a posição onde crise== 1
pos1
table(crise)
prop.table(table(crise))
crise = xts(crise, order.by = data1)
colnames(crise) = 'crise'
# var2
crise2 = matrix(nrow = length(cmts))
crise2 = ifelse(cm2<var2, 1, 0)
pos2 = which(crise2==1)   # pegar a posição onde crise== 1
pos2
for(i in 1:length(pos2)){
a = (pos2[i]-12)
if(a<0){
a = 1
}
crise2[a:pos2[i]] = 1
}
pos3 = which(crise2==1)   # pegar a posição onde crise== 1
pos3
crise = matrix(nrow = length(cmts))
crise = ifelse(cm2<var1, 1, 0)
pos0 = which(crise==1)   # pegar a posição onde crise== 1
pos0
for(i in 2:length(pos)){
crise[(pos[i]-12):pos[i]] = 1
}
pos1 = which(crise==1)   # pegar a posição onde crise== 1
pos1
table(crise)
prop.table(table(crise))
crise = matrix(nrow = length(cmts))
crise = ifelse(cm2<var1, 1, 0)
pos0 = which(crise==1)   # pegar a posição onde crise== 1
pos0
for(i in 2:length(pos0)){
crise[(pos0[i]-12):pos0[i]] = 1
}
pos1 = which(crise==1)   # pegar a posição onde crise== 1
pos1
table(crise)
prop.table(table(crise))
crise = xts(crise, order.by = data1)
colnames(crise) = 'crise'
View(crise)
View(crise)
crise2[c(1, 2)]
crise2
data = index(cmts)
data = data[-c(1, 2)]
c2 = crise2[-c(1, 2)]
crise = xts(crise[-c(1, 2)], order.by = data)
crise2 = xts(crise2[-c(1, 2)], order.by = data)
View(crise2)
av = av$av[data]
rvix = rvix[data]
rav = rav[data]
cb = cb[data]
vix = vix[data]
data = index(cb)
oil =oil[data]
vix = vix[data]
crise = crise[data]
cdi = cdi[data]
ret = ret[data]
gold = gold[data]
embi = embi[data]
cmts = cmts[data]
rexc = rexc[data]
df = data.frame(ret, vix, cb, crise, cdi, embi, crise2, oil, gold, rav, rvix, av, cmts, rexc)
View(df)
saveRDS(df, 'df.rds')
setwd("D:/Git projects/college_works/eco_fin")
# functions
metrics = function(cm){
acurácia = (cm[["table"]][1,1] + cm[["table"]][2,2])/sum(cm[["table"]])
cpc = cm[["table"]][2,2] / ( cm[["table"]][1,2] + cm[["table"]][2,2] )
epc = cm[["table"]][1,1] / ( cm[["table"]][2,1] + cm[["table"]][1,1] )
sensibilidade = cm[["table"]][1,1] / ( cm[["table"]][1,1] + cm[["table"]][2,1] )
especificidade = cm[["table"]][2,2] /( cm[["table"]][2,2] + cm[["table"]][1,2] )
G = sqrt(sensibilidade*especificidade)
LP = sensibilidade/(1 - especificidade)
LR = (1 - sensibilidade)/(especificidade)
DP = sqrt(pi)/3 * ( log(sensibilidade/(1 - sensibilidade) ) + log( especificidade/(1 - especificidade) )  )
gamma = sensibilidade - (1 - especificidade)
BA = (1/2) * (sensibilidade + especificidade)
métricas = data.frame(acurácia, cpc, epc, sensibilidade, especificidade, G, LP, LR, DP, gamma, BA)
}
# libraries
library('xtable')
library(caret)
library(ROSE)
library('randomForest')
df1 = readRDS('df.rds')
View(df1)
keep = c('crise2', 'gold',  'embi',  'oil', 'cb', 'rexc',  'cdi')
df6 = df1[,keep]
library(ROSE)
df3 = ovun.sample(as.factor(crise2)~., data=df6, method="both", p=0.50,
subset=options("subset")$subset,
na.action=options("na.action")$na.action, seed=1)
df3 = data.frame(df3$data)
prop.table(table(df3$crise2))
control_train = trainControl(method = 'repeatedcv', number = 10, repeats = 20)    # ten fold
model_d = train(as.factor(crise2) ~  gold + embi + oil + cb  + cdi, data=df3,
trControl = control_train,
method='multinom',
family='binomial',
maxit=200)
cm_lg1 = confusionMatrix(model_d)
predict(model_d, newdata = df3[,-1],  type = "raw" )
confusionMatrix(model_d)
model_h =train(as.factor(crise2) ~  gold + embi + oil + cb + cdi, data=df3,
trControl = control_train, method='rf')
cm_rf1 = confusionMatrix(model_h)
confusionMatrix(model_h)
