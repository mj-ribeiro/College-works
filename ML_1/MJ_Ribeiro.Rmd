
---
title: "Forecast financial crisis in brasilian stock market using Naive Bayes"
author: "Marcos J Ribeiro"  
institute: 'FEARP-USP'  
date: "19/05/2020"
fontsize: 10pt
output:
  beamer_presentation:
    theme: "AnnArbor"
    colortheme: "dolphin"
    fonttheme: "structurebold"
    slide_level: 2
urlcolor: blue
---
 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "D:/Git projects/college_works/ML_1")
```


```{r include=FALSE}
source("D:/Git projects/college_works/ML_1/Nbayes2_work.R")
```



## My Machine Learning work

- I  built Naive Bayes algorithm to solve classification problems

- I used R language, version 4.0, to do this

- This presentation was built using Beamer Rmarkdown

- My Naive Bayes algorithm and this presentation can be view in my [Github](https://github.com/mj-ribeiro/College-works/tree/master/ML_1). This presentation can also be seen in my [Rpubs](https://rpubs.com/mj-ribeiro/616774)

- First, i will apply my algorithm in four data sets. The first two are simple

- After, i will apply my algorithm  in brasilian stock market to identified crisis. This is my principal analysis

- I will try to predict the crash of brasilian stock market during COVID-19 pandemic

- There are two types of independent variables: Categorical and non-categorical 

- The approach to classification in this context is diferent

- So, i built two functions to solve this, and put this two functions inside one

## Naive Bayes function

- I created two functions: one to be used in datasets with categorical independent variables and the other to be used in datasets with non-categorical independent variables

```{r echo=TRUE}
naivef = function(k, df, cd=1){
    if(cd == 1){
      naive_marcos(k, df)
    }else if (cd == 0){
      naive_marcos2(k, df)
    }else{
      cat('Type cd = 1 for categorical dependent variables, \n
      and cd = 0 for non-categorical dependent variables.')
    }} 
```

- If cd=1 the algorithm can be used in classification problems with categorical dependent variables (naive_marcos)
- If cd=0 the algorithm can be used in classification problems with non-categorical dependent variables (naive_marcos2)


## Naive Bayes function

- k is the class
- df is the data frame that contains the dataset of interest
- My predict function can be see below

```{r echo=TRUE}
predf = function(k, df, df_n, cl, cclas=0, cd=1){
  if(cd == 1){
    pred_marcos(k, df, df_n, cl, cclas)
  }else if (cd == 0){
    pred_marcos2(k, df, df_n, cl, cclas)
  }else{
    cat('Type cd = 1 for categorical dependent variables, 
    \n and cd = 0 for non-categorical dependent variables.')
  }} 
```

- df_n is the new data set that we want to predict the class
- cl is the inductor
- cclas gives the class if cclas=1, and probabilities if cclas=0 



## My first example (default risk)

- There are three attributes in dependent variable (risco) and two independents variables. The independent variables (historia, divida) are categoricals as you can see in head table of my data set:
```{r echo=FALSE}

#df = read.csv('naive_base.csv')
df$garantias =NULL
df$renda =NULL
knitr::kable(head(df), caption = 'Dataset with categorical independent variables', label = 'Elaborate by author.')
```

- Risco is a default risk that the bank runs when lending money
- Historia is customer credit history and divida is customer debt in market  
- So, I will predict if the new customer is a good customer

## Plots

- I use ggplot to plot my data set. 
- Note that credit history is important to predict risk default

```{r echo=FALSE, fig.height=3.5, fig.width=6.12, warning=FALSE}
library(ggplot2)
ggplot(data=df, aes(x=divida, y=historia, colour=risco)) + geom_point(size=5)+
geom_abline(xintercept=2, slope = 1.2) 
```


## Inductor to categorical dependet variables

- I used naivef function in my dataset
```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=TRUE}
cl = naivef('risco', df, cd=1)

```
- This function return a table that contains conditional probabilities 
- This table was save in cl object



## Inductor to categorical dependet variables

- cl object is a tensor
- The tensor has a dimension equal to the number of the class attributes. In this case three
- You can see below the first dimension of this tensor 
- The first row of first column is: $$P(alta, boa|alto)= 0.04761$$

```{r}
head(cl[, ,1])
```

## Predict

- I have six new customers and i want to know if they are good payers
- My new data set can be see below
```{r echo=FALSE}
knitr::kable(head(df_teste), caption = 'New data set with categorical independent variables', label = 'Elaborate by author.')
```

- To do this i used predf function


## Predict
- Here, i used cclas = 0, so, my function return the probabilities of risk associated with my new client

```{r echo=TRUE}
predf('risco', df, df_teste, cl, cclas = 0, cd=1)

```


## Predict

- Here, i used cclas = 1, so, my function return the attribute of my new client
- Recall that cd=1 is to categorical independent variables
```{r echo=TRUE}
predf('risco', df, df_teste, cl, cclas = 1, cd=1)

```


## Quality control

- Here only to verify if my algorith is correct i compared to Naive Bayes produced by library e1071

```{r echo=TRUE}
library(e1071) 
clas2 = naiveBayes(x=df[-3], y = as.factor(df$risco))
prev2 = predict(clas2, newdata = df_teste) 
print(prev2) 
```
- The answers of my algorithm and e1071 are identical


## My second example

- I have two attributes in dependent variable (sex) and two independent variables, weight and height
- Weight and height are non-categorical as you can see in head table of my data set

```{r echo=FALSE}
knitr::kable(head(teste), caption = 'Data set with non categorical independent variables', label = 'Elaborate by author.')
```

- Height and weight are characteristics of the individual
- And i will predict your sex based in this variables


## Plots

- I use ggplot to plot my data set. Note that male is havier than female
- And on average, the man is taller
```{r echo=FALSE, fig.height=3.5, fig.width=6, warning=FALSE}
library(ggplot2)
ggplot(data=teste, aes(x=weight, y=height, colour=sex)) + geom_point(size=5)+
geom_vline (xintercept =  160) + geom_hline (yintercept =  5.55)
```


## Inductor to non-categorical dependet variables

```{r echo=TRUE}
cl2 = naivef('sex', teste, cd=0)
```

- This function return a table that contains conditional probabilities
- This table was save in cl2 object

## Inductor to non-categorical dependet variables

- cl2 is a tensor that contains the two first moments of height and weight by sex. As you can see below
- The tensor has a dimension equal to the number of the class attributes
```{r echo=TRUE}
cl2
```

## Predict

- I have four new people and i want to know if they are male or female
- My new data set can be see below

```{r echo=FALSE}
knitr::kable(head(dfn), caption = 'New data set with non categorical independent variables', label = 'Elaborate by author.')
```

- So, i used predf function to predict the attribute of people

## Predict

- cclas = 1 returns the attribute of new people

```{r}
predf('sex',teste, dfn, cl2, cclas =1, cd=0)
```


## Predict

- cclas = 0 returns the probabilities of the people to be male or female

```{r}
predf('sex',teste, dfn, cl2, cclas =0, cd=0)
```

## Quality control

- Here only to verify if my algorith is correct i compared to Naive Bayes
produced by library e1071

```{r}
library(e1071) 
clas3 = naiveBayes(x=teste[-3], y = teste$sex)
prev3 = predict(clas3, newdata = dfn, 'raw')
print(prev3)
```

- The answers of my algorithm and e1071 are identical



## My third example

- I have two attributes in dependent variable (income) and two independent variables,
occupation and education. The levels of variables can be seen on the next slide
- My independent variables are categorical
- So, I want to predict the income based in occupation and education
- My data set have 30162 observations

```{r echo=FALSE}
knitr::kable(head(census), caption = 'Census dataset head', label = 'Elaborate by author.')
```



## My third example

```{r echo=FALSE}
knitr::kable(a) 
```


## Plots
- How do you see in figure below, education seems to be an important factor in determining the level of income

```{r echo=FALSE, fig.height=3.5, fig.width=6.2, message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(data=census, aes(x=education, y=occupation, colour=income)) + geom_point(size=3.8)+
theme(axis.text.x = element_text(angle = 90)) + geom_vline(xintercept = 8.5) 
```



## Inductor to categorical dependet variables

- I used 28000 observations to train, and 2161 to test my algorithm

```{r echo=TRUE}
tr1 = census[1:28000, ]
tst1 = census[28001:30162, ]
cl4 =  naivef('income', tr1, cd=1)
```


## Predict

- I used cclas = 0, so, my function return the probabilities of income be >50K or <=50k
```{r}
head(predf('income', tr1, tst1, cl4, cclas=0, cd=1))
```


## Predict

- Here I used cclas = 1, so, my function return the class the attribute
```{r}
ndp = predf('income', tr1, tst1, cl4, cclas=1, cd=1)
head(ndp)
```


## Predict

- The acurracy of my algorithm in this case is 75.16%

```{r}
acurracy1 = (sum((ndp==tst1[,'income'])*1)/length(tst1[,1])) *100
acurracy1 
```


## Predict financial crisis using my algoritm

- I want predict crisis in brasilian stock market
- One of the most important models in finance is CCAPM. The complete derivation of the model can be view in my [Github](https://mj-ribeiro.github.io/ecofin.pdf)
- The principal equation of the model is:

\begin{equation}\label{eq12}
	E(R^i_{t+1}) - R^f_{t+1} = \lambda_{g_{t+1}} \beta_{i,g_{t+1}}
\end{equation}

where

\begin{equation}\label{eq13}
	\beta_{i,g_{t+1}} = \left(\frac{Cov_t(g_{t+1}, R_{t+1})}{Var_t(g_{t+1})} \right) 
\end{equation}

and

\begin{equation}\label{eq14}
	\lambda_{g_{t+1}} = \gamma Var_t(g_{t+1})
\end{equation}


## Predict financial crisis using my algoritm
- $R^i_{t+1}$ is the return of asset i
- $R^f_{t+1}$ is the risk free asset
- The left side of the equation is known as the risk premium
- $g_{t+1}$ is the consumption growth
- $t$ is a time subscript
- $\gamma$ is the risk aversion and $\beta$ the price of risk
- I will not go into the details of the model so as not to lose the focus of the work
- My claim is that i can predict crisis in brasilian stock market using risk aversion $\gamma$
- Just create a variable that represents crisis in the stock market brasilian,  create a proxy for risk aversion $\gamma$, and choice other dependent variable


## Crisis proxy

- To make a crisis proxy i create CMAX algorithm to  detects extreme price levels, in Ibovespa returns,  over a given period (12 months for example)
- CMAX equation can be see below

\begin{equation}\label{eq15}
  CMAX_t = \frac{p_t}{max(p_{t-12},\dotsb,p_t)}
\end{equation}


## Crisis proxy

- And my  CMAX algorithm is:

```{r echo=TRUE, warning=FALSE}
CMAX = function(w, n, s){
  l = matrix(nrow=n,ncol = (w+1))
  max = matrix(nrow=n, ncol = 1)
  cmax = matrix(nrow=n, ncol = 1)
  for (j in 1:n){
    
    l[j, 1:(w+1)] = s[j:(w+j)]
    max[j] = max(l[j, 1:(w+1)])
    
    cmax[j] = l[j, (w+1)]/max(max[j])
  }
  return(cmax)
}

```


## Crisis proxy
- w is the window size
- n is the number of windows
- s is the vector that i will pass the function
- If the CMAX exceeds a certain limit, we can say that it is a crisis period and the crisis proxy will be equal to 1. Otherwise, it will be zero
- This limit can be the Value at Risk in 5\%

## Ibovespa returns
- Note the big drop of ibov in 2020 in the figure (a) below. The vertical line in figure (b) is the limit used to define crisis. This is the quantile of 0.05 of Ibovespa returns. This approach is known as Value at Risk (Var)
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=3.5, fig.width=6}
library(quantmod)
ibov = getSymbols('^BVSP', src='yahoo', 
                  from= '2000-03-01', 
                  to = '2020-04-01',
                  periodicity = "monthly",    
                  auto.assign = F)[,4]
par(mfrow=c(1,2))
plot(index(ibov), as.vector(ibov) , main='Evolution\n of Ibovespa \n(a)', type='l', ylab='Ibov', xlab='Time')
hist(find$ret, col='lightgreen', probability = T, main = 'Histogram of Ibovespa\n returns \n(b)', 
     xlab = 'returns', breaks=35 )
abline(v =quantile(find$ret, 0.05))
```



## Non-categorical dependent variables

- The other two variables that i choose is PCA and oil price
- PCA was constructed using Principal Component Analysis of return of 23 assets that compose Ibovespa index. The construction of this variable can be view in my [Github](https://github.com/mj-ribeiro/College-works/blob/master/eco_fin/pca_risk_ecofin.R)
- Oil price i get in Yahoo finance using quantmod library
- My data is a monthly time series from 2000-03 to 2020-03
- I use the data 2000-03 to 2019-05 to train model. And 2019-06 to 2020-03 to test model
- This last time interval cover COVID-19 pandemic. During this pandemic (2020-01 to 2020-03) the Ibovespa fell sharply


## Plots

- We can see in the data that there is no obvious pattern that allows the prediction of falls in the Brazilian stock market. But it seems that the stock market falls are associated with lower oil prices 

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height=3.4, fig.width=6.4}
library(ggplot2)
ggplot(data=find2, aes(x=oil, y=pca, colour=as.factor(x))) + geom_point(size=4)
```



## Inductor to crisis forecast in brasilian stock market

- So, i used naivef function in my dataset
```{r echo=TRUE}
tr = find2[1:231, ]
tst = find2[232:241, ]
cl3 = naivef('x',tr, cd=0)

```


## Predict

- I used predf funtion to predict crisis
- I used cclas = 0, so, my function return the probabilities of crisis (x=1)

```{r echo=TRUE}
predf('x', tr, tst, cl3, cclas=0, cd=0)
```

## Predict
- Here I used cclas = 1, so, my function return the class the attribute 

```{r echo=TRUE}
predf('x', tr, tst, cl3, cclas=1, cd=0)
```

## Predict
- The accuracy of my model is 100\%
```{r echo=TRUE}
prev = predf('x', tr, tst, cl3, cclas=1, cd=0)
accuracy = (sum((prev == tst[,1])*1)/length(tst[,1]) )*100
accuracy
```
- This accuracy may have been caused by the fact that the fall in the Brazilian stock market was very sharp

##

\begin{center}
  \huge{Thanks!}
\end{center}